{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import SnowballStemmer\n",
    "import string\n",
    "import nltk\n",
    "from nltk import PorterStemmer\n",
    "import re \n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_filetext=\"/Users/shwetapai/Desktop/amazon_reviews/chatbot.txt\"\n",
    "f=open(path_filetext,'r',errors = 'ignore')\n",
    "textfile=f.read()\n",
    "textfile=textfile.lower()# converts to lowercase\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(textfile)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(textfile)# converts to list of words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions for Lemmatizing and Cleaning Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Function for greetings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_greeting = (\"hello\", \"hi\", \"greetings\",\"hey\",\"how are you\",\"howdy\",\"wazzup\")\n",
    "possible_response = [\"hi\", \"hey\", \"hello\", \"Godd to talk to you\"]\n",
    "\n",
    "# function to define greeting input and responses\n",
    "def sample_greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in input_greeting:\n",
    "            return random.choice(possible_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating tokens for user reponse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    alexa_response=''\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        alexa_response=alexa_response+\"I am sorry! I donot know the answer\"\n",
    "        return alexa_response\n",
    "    else:\n",
    "        alexa_response = alexa_response+sent_tokens[idx]\n",
    "        return alexa_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALEXA: My name is Alexa. I will answer your queries. If you want to exit, type bye\n",
      "What is amazon's fire hd?\n",
      "ALEXA:   all-new fire hd 8 tablet is a powerful tablet with up to 10 hours of battery life, a vibrant 8\" hd display, a 1.3 ghz quad-core processor, 1.5 gb of ram, and dolby audio.\n",
      "what are its most popular features?\n",
      "ALEXA: the most popular features of all-new fire hd 8 tablet are its long battery life, it screen size and display.customers also find it's price attractive and like the alexa app.\n",
      "thanks\n",
      "ALEXA: You are welcome..\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"ALEXA: My name is Alexa. I will answer your queries. If you want to exit, type bye\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ALEXA: You are welcome..\")\n",
    "        else:\n",
    "            if(sample_greeting(user_response)!=None):\n",
    "                print(\"ALEXA: \"+sample_greeting(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words=list(set(word_tokens))\n",
    "                print(\"ALEXA: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ALEXA: Bye! take have a nice day.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
